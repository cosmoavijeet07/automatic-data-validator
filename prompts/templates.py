"""
Adaptive prompt templates for different stages of data validation
"""

from typing import Dict

# Prompt templates

SCHEMA_DETECTION_PROMPT = """
You are a data analysis expert. Analyze the provided dataset samples and generate Python code to detect the optimal schema.

OBJECTIVES:
1. Infer appropriate data types for each column (int, float, str, datetime, bool, categorical)
2. Detect potential date/datetime formats
3. Identify categorical columns vs free-text columns  
4. Assess data quality indicators (nulls, unique values, patterns)
5. Preserve original column order

DATASET SAMPLES:
{data_samples}

REQUIREMENTS:
- Generate executable Python code using pandas
- Create a dictionary called `schema_info` with the following structure:
  {{
    "sheet_name": {{
      "column_name": {{
        "dtype": "detected_type",
        "format": "format_string_if_applicable", 
        "nullable": true/false,
        "unique_values": count,
        "sample_values": [list_of_samples],
        "recommendations": "any_specific_notes"
      }}
    }}
  }}
- Use only pandas, numpy, and built-in Python libraries
- Handle missing values gracefully
- Include error handling

Return only the Python code, no explanations.
"""

DATA_ANALYSIS_PROMPT = """
You are a data quality expert. Generate comprehensive Python code to analyze data quality based on the provided schema.

SCHEMA INFORMATION:
{schema}

OBJECTIVES:
1. Missing value analysis (count, percentage, patterns)
2. Outlier detection using statistical methods (IQR, Z-score)
3. Data consistency checks
4. Duplicate detection
5. Value distribution analysis
6. Data type validation
7. Format validation for dates/strings
8. Referential integrity checks where applicable

ADDITIONAL REQUIREMENTS:
{additional_instructions}

REQUIREMENTS:
- Generate executable Python code using pandas and numpy
- Create a dictionary called `analysis_results` with comprehensive findings
- Include visualizations using plotly for key metrics
- Provide actionable recommendations
- Handle edge cases and errors gracefully
- Focus on practical data quality issues

Return only the Python code, no explanations.
"""

DATA_CLEANING_PROMPT = """
You are a data cleaning specialist. Generate Python code to clean the dataset based on the schema and analysis results.

SCHEMA:
{schema}

ANALYSIS RESULTS:
{analysis_results}

USER FEEDBACK:
{user_feedback}

CLEANING OBJECTIVES:
1. Handle missing values appropriately (imputation, removal)
2. Remove or cap outliers based on business logic
3. Standardize data formats (dates, strings, numbers)
4. Remove duplicates intelligently
5. Enforce data type constraints
6. Apply business rules for data validation
7. Preserve data integrity and relationships

CLEANING STRATEGIES:
- Numeric: Use mean/median for imputation, cap outliers at percentiles
- Categorical: Use mode or create 'Unknown' category
- Dates: Parse and standardize formats, handle invalid dates
- Text: Standardize case, trim whitespace, handle encoding issues
- Duplicates: Keep first occurrence or most complete record

REQUIREMENTS:
- Generate executable Python code using pandas and numpy
- Create `cleaned_dataframes` dictionary with same structure as input
- Preserve original data relationships
- Add data quality flags where appropriate
- Include logging of all cleaning operations
- Handle errors gracefully with clear error messages

Return only the Python code, no explanations.
"""

CODE_FIX_PROMPT = """
The following code encountered an error. Fix the code while maintaining its original functionality.

ORIGINAL CODE:
{original_code}

ERROR MESSAGE:
{error_message}

TRACEBACK:
{traceback}

REQUIREMENTS:
- Fix the specific error without changing the core logic
- Maintain all variable names and expected outputs
- Add error handling to prevent similar issues
- Keep the code structure as similar as possible
- Add brief comments explaining the fix

Return only the corrected Python code, no explanations.
"""

SCHEMA_EDIT_PROMPT = """
You are a data schema expert. Modify the existing schema based on natural language instructions.

CURRENT SCHEMA:
{current_schema}

USER INSTRUCTIONS:
{instructions}

REQUIREMENTS:
- Apply the requested changes to the schema
- Maintain schema structure and format
- Validate that changes are technically feasible
- Add appropriate format specifications for dates/times
- Preserve existing settings where not explicitly changed
- Return updated schema in the same format

Return only the modified schema as JSON, no explanations.
"""

PIPELINE_COMBINATION_PROMPT = """
#!/usr/bin/env python3
\"\"\"
Automated Data Cleaning Pipeline
Generated by Automated Data Validator
\"\"\"

import pandas as pd
import numpy as np
import json
from datetime import datetime
from typing import Dict, Any, Tuple

# Helper functions
def detect_schema(df_dict: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
    # Schema detection logic
    pass

def analyze_data_quality(df_dict: Dict[str, pd.DataFrame], schema: Dict) -> Dict[str, Any]:
    # Analysis logic
    pass

def clean_data(df_dict: Dict[str, pd.DataFrame], schema: Dict, analysis: Dict) -> Dict[str, pd.DataFrame]:
    # Cleaning logic
    pass

# Main pipeline function
def clean_data_pipeline(df_dict: Dict[str, pd.DataFrame]) -> Tuple[Dict[str, pd.DataFrame], Dict[str, Any]]:
    \"\"\"Main data cleaning pipeline\"\"\"
    pass

if __name__ == "__main__":
    # CLI interface
    pass
"""

def get_prompt_template(template_name: str) -> str:
    """Get a specific prompt template by name"""
    templates = {
        'schema_detection': SCHEMA_DETECTION_PROMPT,
        'data_analysis': DATA_ANALYSIS_PROMPT,
        'data_cleaning': DATA_CLEANING_PROMPT,
        'code_fix': CODE_FIX_PROMPT,
        'schema_edit': SCHEMA_EDIT_PROMPT,
        'pipeline_combination': PIPELINE_COMBINATION_PROMPT
    }

    if template_name not in templates:
        raise ValueError(f"Template '{template_name}' not found.")
    return templates[template_name]
